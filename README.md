# ğŸš€ Distributed CPU Training on FEP (SLURM)

## ğŸ† Introduction

The main goal of this project is to implement a **distributed training model** on multiple **microprocessors (CPUs)**. This process is automated and runs on the **FEP infrastructure**, specifically using **SLURM**, which is a **cluster of computers located at UPB, in the PRECIS building**. 

ğŸ› ï¸ **Technology Stack:**
- **MPI (`mpi4py`)** for parallel processing ğŸ”„
- **SLURM Cluster** for distributed training âš¡
- **NumPy** for numerical computations ğŸ“Š

Each process **independently performs forward and backward propagation**, where the user implements **backpropagation** instead of relying on built-in functions (e.g., `autograd`, `backward`, `forward`). Once all gradients are computed, they are synchronized using `allreduce` to update the model parameters.

---

## ğŸ“Œ Project Implementation Plan

This project follows a **systematic approach** to developing a **distributed machine learning model** across **multiple CPU cores**. It is built using the `mpi4py` library, which allows computational tasks to be distributed among multiple processes. 

ğŸ”¥ **Key Features:**
âœ”ï¸ Each MPI process runs on a **separate CPU core** ğŸ—ï¸  
âœ”ï¸ Synchronization between processes is achieved using **`MPI.Allreduce`** ğŸ”„  
âœ”ï¸ No **PyTorch, CUDA, or GPUs** involvedâ€”all computations are done on **CPUs only** ğŸ–¥ï¸

The number of processes is specified using the command:
```sh
mpirun -np <num_processes> python3 distributed_training.py
```
ğŸ’¡ **Example:** Running **4 processes**:
```sh
mpirun -np 4 python3 distributed_training.py
```
Each process computes gradients **independently** and synchronizes them using `MPI.Allreduce`.

### âš¡ Standard Output Display
ğŸ–¥ï¸ **Important Notes:**
- The `stdout` output is **shared** among all processes ğŸ“¢
- Messages from **different processes may appear out of order** due to execution speeds â³
- Some processes may receive **more resources**, completing tasks faster âš¡

---

## ğŸ“Š Results

### ğŸ“œ Example Log Output:
```sh
Process 1 is running on this node.
Process 1, Epoch 1: grad_W mean = -0.0283, grad_b mean = -0.0010
Process 1, Epoch 1: Contribution to W = 8.99%, b = 0.05%
Process 1, Epoch 1: Sync time = 0.201988 seconds
...
Process 0, Epoch 10: grad_W mean = -0.2028, grad_b mean = -0.3872
Process 0, Epoch 10: Contribution to W = 23.67%, b = 20.40%
Process 0, Epoch 10: Sync time = 0.000069 seconds
```

### ğŸ“Œ Model Parameters After Training:
```sh
W:
9.505355511359944720e-02
8.608506196416068068e-01
...

b:
1.276012244831889186e-01
```

### â±ï¸ Synchronization Time Per Epoch
| ğŸ·ï¸ Epoch | â³ Sync Time (s) |
|---------|----------------|
| 1ï¸âƒ£  | 0.285622 |
| 2ï¸âƒ£  | 0.013190 |
| 3ï¸âƒ£  | 0.000103 |
| ...  | ...        |
| ğŸ”Ÿ  | 0.000069 |

---

## ğŸ” Interpretation of Results

ğŸ“Œ **Key Observations:**
âœ”ï¸ The **distributed process functions correctly** across multiple **CPU cores** ğŸ”„  
âœ”ï¸ Some processes contribute **more** to gradient updates than others, indicating **data imbalance** âš ï¸  
âœ”ï¸ **Synchronization time drops significantly** after the first epoch â±ï¸  
âœ”ï¸ The model parameters may not be **optimal**, possibly due to **uneven data distribution** ğŸ“‰  

ğŸ“¢ **Process Contributions:**
- Process **2 contributes disproportionately** (>110% for `W` and `b`), meaning **data balancing is needed** âš–ï¸
- Processes **0, 1, and 3** contribute **20-23%, 9-10%, and 12%** respectively ğŸ”„

---

## ğŸ Conclusion

âœ… **Project Achievements:**
âœ”ï¸ Successfully demonstrated **distributed training** across multiple **CPU cores** ğŸ—ï¸  
âœ”ï¸ Verified that each process **correctly receives and processes its assigned data** ğŸ“Š  
âœ”ï¸ Implemented an efficient **MPI-based synchronization mechanism** ğŸ”„  

ğŸš€ **Future Improvements:**
- **Optimize data distribution** among processes for better **gradient contribution balance** ğŸ“‰  
- **Investigate hyperparameter tuning** to improve **model convergence** ğŸ”¬  
- **Enhance debugging mechanisms** for tracking individual process contributions ğŸ› ï¸  

---

## ğŸ›¡ï¸ References
ğŸ“Œ For full references, please see the [Full PDF Document](https://github.com/mateineaga/Distributed-CPU-training-on-a-cluster-of-computers/blob/main/Distributed-CPU-training-on-a-cluster-of-computers.pdf).

---